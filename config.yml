########################################################################################################################
#                                                                                                                      #
#                                           PlasmaNet -- Configuration file                                            #
#                                                                                                                      #
#                                      Guillaume Bogopolsky, CERFACS, 11.03.2020                                       #
#                                                                                                                      #
########################################################################################################################

# Contains the parameters for the model (training, etc.)

# To import the parameters, use
#     import yaml
#     with open('config.yml', 'r') as yaml_stream:
#         config = yaml.safe_load(yaml_stream)

# The train routine will automatically load the required `type` of each section with the given `args` by using the
# `config.init_obj` method.


name: 'dh_photo_UNet'                      # Experience name
n_gpu: 1                                    # Number of GPUs to use

globals:                                    # Domain sizes and others, used to compute global attributes
    nnx: 401
    nny: 101
    lx: 0.004
    ly: 0.001
    coord: 'cyl'

arch:
    type: 'UNet'
    args:
        data_channels: 1                    # For dirichlet use 2 or 3, and keep 1 or 5 for the homogeneous problem 

data_loader:
    type: 'PhotoDataLoader'
    pipe_config: True
    args:
<<<<<<< HEAD
        data_dir: '/scratch/cfd/cheng/DL/plasmanet/CfdSolver/data/dh_streamer_2'
        batch_size: 64
=======
        data_dir:  '/scratch/cfd/ajuria/Plasma/plasmanet/datasets/64x64/rhs/random_64_4_interpolated_3_scales/'
        #data_dir: '/scratch/cfd/bogopolsky/DL/plasmanet/datasets/128x128/rhs/random_128_4_split0.75_filtered500Hz/'
        batch_size: 256
>>>>>>> scale_analysis_dev_2
        shuffle: True
        validation_split: 0.2               # if float, fraction of the full dataset, if int, length of validation portion
        num_workers: 4
        normalize: 'None'                   # max, physical or no for normalization types
        input_cutoff_frequency: 'None'      #Â Low-pass filter of input (float, or None to deactivate)
        guess: 'fourier'                    # Exponential or fourier guess (depending on data channels)      
        modes: 10                           # Number of Fourier modes for the 2D guess

initializer: 'off'

optimizer:
    type: 'Adam'
    args:
        lr: 4.e-4
        weight_decay: 0
        amsgrad: False                      # AMSGrad variant from paper 'On the convergence of Adam and Beyond'

loss:
    type: 'ComposedLoss'
    pipe_config: True                       # Object initialization require config as first argument
    args:
        loss_list:                          # List of the losses to compose if ComposedLoss is used
            - InsideLoss
            - MSInsideLoss_n
            - MSInsideLoss_n2
            - MSInsideLoss_n4
            - DirichletBoundaryLoss
            - PhotoLoss
        inside_weight: 1.                   # Weighting of the loss inside the domain, excluding boundaries (float)
        inside_weight_n : 0.4              # Weighting of the loss inside the domain for the n scale , excluding boundaries (float)
        inside_weight_n2 : 0.4              # Weighting of the loss inside the domain for the n 2 scale , excluding boundaries (float)
        inside_weight_n4 : 0.4              # Weighting of the loss inside the domain for the n 4 scale , excluding boundaries (float)
        bound_weight: 0. #1.                # Weighting of the loss on the boundaries (float)
        elec_weight: 0.                     # Weighting of the loss on the electric field (float)
<<<<<<< HEAD
        lapl_weight: 0.0                    # Weighting of the loss on the Laplacian (float)
=======
        lapl_weight: 0. #0.2                # Weighting of the loss on the Laplacian (float)
>>>>>>> scale_analysis_dev_2

metrics:
    - 'residual'
    - 'l2_norm'
    - 'inf_norm'

lr_scheduler:
    type: 'ReduceLROnPlateau'
    plateau_metric: loss                    # monitoring metric for ReduceLROnPlateau step()
    args:
        mode: 'min'
        factor: 0.9                         # Amount scheduler reduces LR by (float)
        patience: 50                        # Number of epochs the scheduler waits (int)
        threshold: 3.e-4                    # Relative improvement the scheduler must see (float)
        threshold_mode: 'rel'
        verbose: False

trainer:
<<<<<<< HEAD
    epochs: 400
=======
    epochs: 5000 #500
>>>>>>> scale_analysis_dev_2
    save_dir: 'outputs/'
    save_period: 10
    plot_period: 10                         # Period to send plots to TensorBoard
    verbosity: 2
    monitor: min val_loss                   # Monitor best model ('method metric', method={min, max}, metric exists)
    early_stop: 200                         # Training is stopped if model performance does not increase for 50 epochs
    tensorboard: true
<<<<<<< HEAD
    histograms: false                       # Save weights and bias histograms (turned off to increase TensorBoard perf)
=======
    hooks: true
    1_scale: 100                            # Epoch in which the network freezes the 1st scale
    2_scale: 400                            # Epoch in which the middle scale is frozen
>>>>>>> scale_analysis_dev_2
